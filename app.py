import gradio as gr
import theme
import requests
import secrets
import string
import json
import os
from modelscope import (
    HubApi, snapshot_download, AutoModelForCausalLM, AutoTokenizer, GenerationConfig
)

YOUR_ACCESS_TOKEN = "34ea45f6-f624-4de6-9604-2e378dd4d4f7"

api = HubApi()
api.login(YOUR_ACCESS_TOKEN)

model_zh = snapshot_download("QiYuan-tech/LLM-Detector-Small-zh",revision = "v1.0.0")
model_en = snapshot_download("QiYuan-tech/LLM-Detector-Small-en",revision = "v1.0.0")

tokenizer_zh = AutoTokenizer.from_pretrained(model_zh, trust_remote_code=True)
model_zh = AutoModelForCausalLM.from_pretrained(model_zh, device_map="auto", trust_remote_code=True).eval()

tokenizer_en = AutoTokenizer.from_pretrained(model_zh, trust_remote_code=True)
# GPU
model_en = AutoModelForCausalLM.from_pretrained(model_zh, device_map="auto", trust_remote_code=True).eval()

# pip install gradio==3.50.2 -i https://pypi.tuna.tsinghua.edu.cn/simple
#os.system("pip install gradio==3.50.2 -i https://pypi.tuna.tsinghua.edu.cn/simple")
#os.system("pip install bitsandbytes -i https://pypi.tuna.tsinghua.edu.cn/simple")

default_css = """\
<style type="text/css">
    .diff {
        border: 1px solid #cccccc;
        background: none repeat scroll 0 0 #f8f8f8;
        font-family: 'Bitstream Vera Sans Mono','Courier',monospace;
        font-size: 12px;
        line-height: 1.4;
        white-space: normal;
        word-wrap: break-word;
    }
    .diff div:hover {
        background-color:#ffc;
    }
    .diff .control {
        background-color: #eaf2f5;
        color: #999999;
    }
    .diff .insert {
        background-color: #ddffdd;
        color: #000000;
    }
    .diff .insert .highlight {
        background-color: #aaffaa;
        color: #000000;
    }
    .diff .delete {
        background-color: #ffdddd;
        color: #000000;
    }
    .diff .delete .highlight {
        background-color: #ffaaaa;
        color: #000000;
    }
</style>
"""

title = "<h1 style='text-align: center; color: #333333; font-size: 40px;'> ğŸ” LLM-Detector </h1>"
description = """
LLM-Detector
"""

style = theme.Style()

def generate_random_string(length):
    characters = string.ascii_letters + string.digits
    return ''.join(secrets.choice(characters) for _ in range(length))

def infer(select_model, input_text):
    predictions = []
    
    folder_path = './data/'
    file_name = generate_random_string(32)
    
    if select_model=="LLM-Detector-Small-zh":
        #global model_zh
        #tokenizer_zh = AutoTokenizer.from_pretrained(model_zh, trust_remote_code=True)
        #model_zh = AutoModelForCausalLM.from_pretrained(model_zh, device_map="auto", trust_remote_code=True).eval()
        #model_zh = AutoModelForCausalLM.from_pretrained("./ZH", device_map="auto", trust_remote_code=True).cuda()
        
        llm_results, history = model_zh.chat(tokenizer_zh, input_text, history=None)

        if llm_results=="Human":
            predicted_labels = "ğŸ‘¨â€ğŸ”§ è¿™æ®µæ–‡æœ¬ç”±äººç±»ç”Ÿæˆï¼"
            predictions.append((str(input_text), "äººç±»"))
        if llm_results=="AI":
            predicted_labels = "ğŸ¤– è¿™æ®µæ–‡æœ¬ç”±AIç”Ÿæˆï¼"
            predictions.append((str(input_text), "AI"))
        
        json_data = {
                "text": str(input_text),
                "label": llm_results
        }
        
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
        
        with open(folder_path+file_name+'.json', 'w', encoding='utf-8') as json_file:
            json.dump(json_data, json_file, indent=4, ensure_ascii=False)
        gr.Textbox.update(visible=False)
        return predicted_labels, predictions, folder_path+file_name+'.json'
    
    if select_model=="LLM-Detector-Small-en":
        #global model_en
        #tokenizer_en = AutoTokenizer.from_pretrained(model_zh, trust_remote_code=True)
        # GPU
        #model_en = AutoModelForCausalLM.from_pretrained(model_zh, device_map="auto", trust_remote_code=True).eval()
        #model_en = AutoModelForCausalLM.from_pretrained("./EN", device_map="auto", trust_remote_code=True).cuda()
        
        llm_results, history = model_en.chat(tokenizer_en, input_text, history=None)
        
        if llm_results=="Human":
            predicted_labels = "ğŸ‘¨â€ğŸ”§ è¿™æ®µæ–‡æœ¬ç”±äººç±»ç”Ÿæˆï¼"
            predictions.append((str(input_text), "äººç±»"))
        if llm_results=="AI":
            predicted_labels = "ğŸ¤– è¿™æ®µæ–‡æœ¬ç”±AIç”Ÿæˆï¼"
            predictions.append((str(input_text), "AI"))
        
        json_data = {
                "text": str(input_text),
                "label": llm_results
        }
        
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
        
        with open(folder_path+file_name+'.json', 'w', encoding='utf-8') as json_file:
            json.dump(json_data, json_file, indent=4, ensure_ascii=False)
    
        return predicted_labels, predictions, folder_path+file_name+'.json'
    else:
        return "è¯·é€‰æ‹©æ¨¡å‹", "è¯·é€‰æ‹©æ¨¡å‹", folder_path+file_name+'.json'

with gr.Blocks(theme=style) as demo:
    #gr.Markdown(title)
    #gr.Markdown(description)
    with gr.Row():
        with gr.Column():
            select_model = gr.Dropdown(["LLM-Detector-Small-zh", "LLM-Detector-Small-en"], label="æ¨¡å‹é€‰æ‹©", info="è¯·é€‰æ‹©é€‚åˆæ–‡æœ¬å†…å®¹çš„æ£€æµ‹æ¨¡å‹(ğŸ½ï¸ç›®å‰æ”¯æŒä¸­æ–‡/è‹±æ–‡æ£€æµ‹ï¼Œæ ‡è®°æ¨¡å‹å³å°†æ¨å‡º)ï¼š", value='LLM-Detector-Small-zh')
            input_text = gr.Textbox(label="æ–‡æœ¬å†…å®¹", lines=20, autofocus=True, info="è¯·è¾“å…¥ä½ çš„æ–‡æœ¬å†…å®¹ï¼ŒLLM-Detectorå°†åˆ¤æ–­å®ƒæ˜¯ç”±AIè¿˜æ˜¯äººç±»ç”Ÿæˆçš„ï¼š", show_copy_button=True, placeholder="è¯·è¾“å…¥æ‚¨çš„æ–‡æœ¬...")
            submit = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
            gr.Markdown("- ğŸ”´ç»§ç»­åˆ™è¡¨ç¤ºæ‚¨**åŒæ„å¹¶æ¥å—æˆ‘ä»¬æ”¶é›†æ‚¨æäº¤çš„æ–‡æœ¬å†…å®¹**ï¼è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯¹äº**é€šè¿‡æ£€æµ‹è·å¾—çš„ç»“æœä¸è´Ÿè´£ä»»**ã€‚\n - ğŸ”µè¯¥é¡¹ç›®**ä»…ç”¨äºå­¦æœ¯ç ”ç©¶**ä¸å¯ç”¨äºå•†ä¸šç”¨é€”ï¼")
            
        with gr.Column(): # "Results", open=False
            label = gr.Label(label="é¢„æµ‹ç»“æœ")
            highlighted_prediction = gr.HighlightedText(
                                    label="æ–‡æœ¬åˆ†æ",
                                    combine_adjacent=True,
                                    color_map={"AI": "red", "äººç±»": "green"},
                                    show_legend=True)
            save_data = gr.File(label="ä¿å­˜ç»“æœ")

    submit.click(infer, inputs=[select_model, input_text], outputs=[label, highlighted_prediction, save_data])
    
    gr.Markdown("## ğŸ‘ï¸â€ğŸ—¨ï¸ç¤ºä¾‹æµ‹è¯•")
    gr.Markdown("#### äººç±»æ–‡æœ¬ç¤ºä¾‹")
    gr.Examples(
        [
        ["LLM-Detector-Small-zh", "ç›®å‰,åŸºäºæœºå™¨è§†è§‰çš„è½¦è¾†æ£€æµ‹ç®—æ³•å­˜åœ¨æ£€æµ‹é€Ÿåº¦è¾ƒæ…¢çš„é—®é¢˜ã€‚é’ˆå¯¹è¯¥é—®é¢˜,æå‡ºä¸€ç§åŸºäºYOLOç®—æ³•çš„è½¦è¾†å®æ—¶æ£€æµ‹æ–¹æ³•ã€‚YOLOæ£€æµ‹ç®—æ³•çš„åŸºæœ¬æ¨¡å‹ç”±å·ç§¯å±‚,æ± åŒ–å±‚ä»¥åŠå…¨è¿æ¥å±‚ç»„æˆ,å…·æœ‰å¼ºé²æ£’æ€§ä»¥åŠèƒ½å¤Ÿå¿«é€Ÿå®Œæˆè½¦è¾†æ£€æµ‹ä»»åŠ¡ã€‚é€‰æ‹©äº¤é€šç›‘æ§è§†é¢‘ä½œä¸ºæ•°æ®é›†è¿›è¡Œè½¦è¾†æ£€æµ‹è¯•éªŒã€‚ç»“æœè¡¨æ˜,YOLOæ£€æµ‹ç®—æ³•çš„æŸ¥å‡†ç‡ä¸º89.3%,æŸ¥å…¨ç‡ä¸º81.0%,æ£€æµ‹é€Ÿåº¦è¾¾åˆ°60f/s,åŸºæœ¬æ»¡è¶³äº¤é€šç›‘æ§ä¸­è½¦è¾†æ£€æµ‹çš„å®æ—¶æ€§éœ€æ±‚,è¯´æ˜è¯¥æ–¹æ³•åˆç†å¯è¡Œã€‚è¿ç”¨è¯¥æ–¹æ³•ä¸2ç§ä¸åŒçš„æ£€æµ‹ç®—æ³•è¿›è¡Œå¯¹æ¯”åˆ†æ,å¾—å‡ºYOLOç®—æ³•çš„æ£€æµ‹é€Ÿåº¦æœ€å¿«ã€‚"],
        ["LLM-Detector-Small-zh", "12æœˆ5æ—¥ï¼Œå›½å®¶ä¸»å¸­ä¹ è¿‘å¹³è‡´ç”µå®‰å¾·é‡ŒÂ·å°¼é‡Œçº³Â·æ‹‰ä¹”åˆ©çº³ï¼Œç¥è´ºä»–å½“é€‰è¿ä»»é©¬è¾¾åŠ æ–¯åŠ å…±å’Œå›½æ€»ç»Ÿã€‚ä¹ è¿‘å¹³æŒ‡å‡ºï¼Œä¸­å›½åŒé©¬è¾¾åŠ æ–¯åŠ ä¼ ç»Ÿå‹å¥½ã€‚è¿‘å¹´æ¥ï¼Œåœ¨æˆ‘ä»¬å…±åŒå¼•é¢†ä¸‹ï¼Œä¸¤å›½å…³ç³»åŠ é€Ÿå‘å±•ï¼Œå„é¢†åŸŸäº¤æµåˆä½œæˆæœä¸°ç¡•ï¼ŒåŒæ–¹åœ¨æ¶‰åŠå½¼æ­¤æ ¸å¿ƒåˆ©ç›Šå’Œé‡å¤§å…³åˆ‡é—®é¢˜ä¸Šåšå®šç›¸äº’æ”¯æŒã€‚æˆ‘é«˜åº¦é‡è§†ä¸­é©¬å…³ç³»å‘å±•ï¼Œæ„¿åŒæ‹‰ä¹”åˆ©çº³æ€»ç»Ÿä¸€é“åŠªåŠ›ï¼Œç»§ç»­æ¨åŠ¨ä¸­é©¬å…¨é¢åˆä½œä¼™ä¼´å…³ç³»å–å¾—æ›´å¤§å‘å±•ï¼Œæ›´å¥½é€ ç¦ä¸¤å›½äººæ°‘ã€‚"],
        ["LLM-Detector-Small-zh","è°¢è°¢æŒ‡ç‚¹è¿·æ´¥ï¼Œä¸¤ä¸ªtimeæ”¹ä¸º365ï¼Œå°å…ƒå»¶ç»­æ—¶é—´èƒ½é•¿ä¸€ç‚¹ï¼Œæˆ‘å‡†å¤‡æ”¹ä¸º3600è¯•è¯•ã€‚ç»è¿‡æ€è€ƒï¼Œrm E2Eç›®å½•åé‡æ–°å»ºç«‹è¿è¡Œæ–‡ä»¶ï¼Œtimeæ”¹ä¸º365ï¼Œå…‹åˆ¶è‡ªå·±ä¸é—®å¤æ‚é—®é¢˜ï¼Œchatbotèƒ½åšæŒä¸‹æ¥ã€‚è¯´å¥å®åœ¨è¯ï¼Œä¸ç®—ååº”é€Ÿåº¦ï¼Œè¿™ä¸ªæ°´å¹³æ¯”chatgpt2.0ç¨å·®ï¼Œæ¯”å¼€å§‹çš„è±†åŒ…å’Œ360æ™ºè„‘èƒ½ç¨å¥½ä¸€ç‚¹ï¼ˆè¿™è¯åªé™äºæ˜‡è…¾è®ºå›è®¨è®ºï¼Œåªæ˜¯ä¸ªäººçœ‹æ³•ï¼‰ï¼Œè€ƒè™‘åˆ°å¼€å‘æ¿çš„ä»·æ ¼ï¼Œè¯´æ˜è½¯ä»¶ä¼˜åŒ–å¾ˆå¥½ï¼Œè¯æ˜åä¸ºç¡¬ä»¶å¼€åŠ chatbotè¡¨ç°è¶…ä¹æƒ³è±¡ã€‚æˆ‘ä¹°äº†æ¿å­å¼€å§‹è¯•éªŒä»…ä»…ä¸€å‘¨æ—¶é—´ï¼Œè¯•éªŒç»“æœè¯´æ˜æ˜‡è…¾ç»„ä»¶ç¡®å®éåŒå‡¡å“ã€‚æœŸå¾…èƒ½å¼€æ”¾ä¸€äº›è°ƒæ•´å‚æ•°ï¼Œæˆ–è€…å¼€æ”¾è®­ç»ƒåº“çš„ç»„æˆå’Œè®­ç»ƒæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€äº›å­¦ä¹ è¾…åŠ©ï¼Œè¿‡å»è¯´å¥½è®°æ€§ä¸å¦‚çƒ‚ç¬”å¤´ï¼Œç°åœ¨æœ‰äº†chatbotèƒœè¿‡å¥½è®°æ€§ï¼Œå¸Œæœ›æ˜‡è…¾ç»„ä»¶èƒ½æ¨å¹¿å¼€æ¥ï¼Œæœ‰æ›´å¹¿æ³›çš„åº”ç”¨ã€‚"],
        ["LLM-Detector-Small-zh", "æˆ‘ä»¬çŸ¥é“ï¼Œå½“äº‹ä»¶Açš„å‘ç”Ÿå¯¹äº‹ä»¶Bçš„å‘ç”Ÿæœ‰å½±å“æ—¶ï¼Œæ¡ä»¶æ¦‚ç‡P(B|A)å’Œæ¦‚ç‡ P(B)ä¸€èˆ¬æ˜¯ä¸ç›¸ç­‰çš„ï¼Œä½†æœ‰æ—¶äº‹ä»¶Açš„å‘ç”Ÿçœ‹ä¸Šå»å¯¹äº‹ä»¶Bçš„å‘ç”Ÿæ²¡æœ‰å½±å“ï¼Œæ¯”å¦‚ä¾æ¬¡æŠ›æ·ä¸¤æšç¡¬å¸ï¼ŒæŠ›æ·ç¬¬ä¸€æšç¡¬å¸çš„ç»“æœ(äº‹ä»¶A)åº”è¯¥å¯¹ç¬¬äºŒæšç¡¬å¸çš„ç»“æœ(äº‹ä»¶B)æ²¡æœ‰å½±å“ï¼Œè¿™æ—¶P(B|A)ä¸P(B)ç›¸ç­‰å—?"],
        ["LLM-Detector-Small-zh", "ç”±è¶…å‡ ä½•åˆ†å¸ƒå’ŒäºŒé¡¹åˆ†å¸ƒç­‰ç¦»æ•£å‹éšæœºå˜é‡çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬çŸ¥é“ç¦»æ•£å‹éšæœºå˜é‡çš„åˆ†å¸ƒåˆ—èƒ½å¤Ÿå®Œå…¨æè¿°éšæœºå˜é‡å–å€¼çš„æ¦‚ç‡è§„å¾‹ã€‚ä½†æ˜¯ï¼Œåœ¨è®¸å¤šå®é™…é—®é¢˜ä¸­ï¼Œè¿˜éœ€è¦äº†è§£ç¦»æ•£å‹éšæœºå˜é‡çš„æŸç§ç‰¹å¾ï¼Œä¾‹å¦‚ç¦»æ•£å‹éšæœºå˜é‡çš„å¹³å‡å–å€¼å¤§å°å’Œå–å€¼çš„é›†ä¸­ç¨‹åº¦ã€‚æˆ‘ä»¬æŠŠè¿™ç§åæ˜ æ¦‚ç‡åˆ†å¸ƒçš„æŸç§ç‰¹å¾çš„æ•°å€¼ï¼Œå«åšç¦»æ•£å‹éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾ï¼Œä¸‹è€Œæˆ‘ä»¬æ¥ä»‹ç»ä¸¤ä¸ªæœ€åŸºæœ¬çš„ç¦»æ•£å‹éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾."],
        ["LLM-Detector-Small-en","In Vauban, Germany, citizens have made the decision to not use cars. To some people, this may be something that they could never imagine themselves doing, because it would make life more complicated. However, these people are pleased with their decision and would not have it any other way. Furthermore, there are many advantages to making this change. By limiting car usage, citizens can improve their own health and economic state.\n\nBy making the decision to stop using cars, one can become healthier, both mentally and physically. One citizen who has already taken this step said,\"when I had a car I was always tense. I'm much happier this way\" Rosenthal 3. Many people who chose to limit their car usage, decided to walk or ride bikes instead. By chosing the alternative, they are less stressed. There is something soothing about walking down the road in a quiet and peaceful environment. Walking gives one time to reflect and think, while driving requires concentration and can be stressful. In addition to improving one's mental health, limiting car usage can also improve one's physical health. Pollution from the air can take a toll on someone's physical health and the environment around them. \"Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe... and up to 50 percent in some carintensive areas in the United States\" Rosenthal 5. Pollution poisons the air of most cities where people live and breathing the pollution is not healthy for an individual. In cities like Beijing, inhabitants wear air filters over their mouths in hopes fo escaping the pollution. Limiting car usage can help improve air quality quickly. For example, after having multiple days of intense smog, Paris decided to ban cars with evennumbered plates for one day. After this one day of limited car usage, \"the smog cleared enough Monday for the ruling French party to rescind the ban for oddnumbered plates on Tuesday\" Duffer 19.\n\nAnother advantage to limiting cars is that it could mean economic improvement for individuals and countries. The banning of cars can mean improvement in the appearance of cities, which can have positive impacts on the economy of cities. \"Parks and sports centers also have bloomed throughout the city uneven, pitted sidewalks have beeen replaced by broad, smooth sidewalks\" Selsky 28. These improvements in the city can draw more people to them and stimulate the economy in places that have had difficulty before. In addition, individuals can save money by carpooling, biking, walking, or using public transit as an alternative optopn to driving. During the 2013 rececession, people were forced to sell their cars due to lack of money. However, after they recovered from this, they decided not to return to car usage due to their content in the lifestyle they had chosen Rosenthal 32 In conclusion, limiting one's usage of cars can have only positive impacts on one's life. This decision can have lasting impacts one's happiness, the environment, and the economy."],
        ["LLM-Detector-Small-en","Dear state senator, I'm writing to you today regarding my concerns on our voting method for the president of the United States. Although we've been voting by the electoral college for how ever many years, I don't think it is the most efficient and fair way of voting. Our Chamber of Commerce, former vice president Richard Nixon and many more would have to agree with me when I say that abolishing the electoral college could only be beneficial to us. The electoral college system is unfair, confusing and forces people to compromise.\n\nThe electoral college is unfair, being that voters don't always control who their electors vote for, opposed to election by popular vote. One reason why America strives is the fact that we are a democracy, where every one gets a say and we are not ruled by a dictators or communist. The electoral college in no way follows our democratic system, the people are not voting for our president our electors are the ones voting for us.\n\nNot only is the electoral college unfair but it is also confusing. For new voters they may be confused by the electoral college. New voters may wonder why can't I just vote for the candidate I most prefer. Think about it like this, in the electoral college the electors are the middle man. Why not cut the middle man out? And as a result make the voting system much simpler.\n\nPeople may agrue that the electoral college system stops a majority vote. So let's say, you're a democrat living in the state of Texas with the electoral college system in place. You might as well not vote for an elector cause the majority of the people in texas are going to vote for the republican elector. On the other hand, there is the election by popular vote, gives everyone a say in whom they'd like to vote for. There is always the possibility of the disater factor.\n\nAfter sharing my concerns with you state senator, I hope you understand where I am coming from."],
        ],
        
        inputs=[select_model, input_text]
    )
    
    gr.Markdown("#### GPT-4æ–‡æœ¬ç¤ºä¾‹")
    gr.Examples(
        [
        ["LLM-Detector-Small-zh", "æ­£æ€åˆ†å¸ƒï¼Œä¹Ÿå¸¸è¢«ç§°ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œæ˜¯ç»Ÿè®¡å­¦ä¸­æœ€ä¸ºé‡è¦çš„æ¦‚ç‡åˆ†å¸ƒä¹‹ä¸€ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬åœ¨ç­çº§é‡Œæµ‹é‡æ‰€æœ‰åŒå­¦çš„èº«é«˜ã€‚ä½ å¯èƒ½ä¼šå‘ç°ï¼Œå¤§éƒ¨åˆ†åŒå­¦çš„èº«é«˜ä¼šé›†ä¸­åœ¨ä¸€ä¸ªå¹³å‡å€¼é™„è¿‘ï¼Œè€Œå¾ˆé«˜æˆ–å¾ˆçŸ®çš„åŒå­¦åˆ™ç›¸å¯¹è¾ƒå°‘ã€‚è¿™ç§ç°è±¡ï¼Œå…¶ä¸­å¤§å¤šæ•°æ•°æ®å›´ç»•ä¸€ä¸ªä¸­å¿ƒå€¼èšé›†ï¼Œå¹¶ä¸”å‘ä¸¤è¾¹é€æ¸å‡å°‘ï¼Œå½¢æˆä¸€ä¸ªé’Ÿå½¢æ›²çº¿ï¼Œå°±æ˜¯æ­£æ€åˆ†å¸ƒçš„å…¸å‹ç‰¹å¾ã€‚"],
        ["LLM-Detector-Small-zh","Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶æ˜“äºå­¦ä¹ å’Œä½¿ç”¨çš„è¯­æ³•ã€å¼ºå¤§çš„åº“å’Œæ¡†æ¶æ”¯æŒï¼Œä»¥åŠå¹¿æ³›çš„åº”ç”¨é¢†åŸŸï¼ˆå¦‚ç½‘ç«™å¼€å‘ã€æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½å’Œè‡ªåŠ¨åŒ–ï¼‰è€Œé—»åã€‚"]
        ],
        inputs=[select_model, input_text]
    )
    
    gr.Markdown("#### ChatGPTæ–‡æœ¬ç¤ºä¾‹")
    gr.Examples(
        [
        ["LLM-Detector-Small-zh", "åœ¨å°é•‡ä¸Šï¼Œä¸€åªä¸¢å¤±çš„å°çŒ«å¼•å‘äº†ä¸€åœºæƒŠå¿ƒåŠ¨é­„çš„å¯»æ‰¾ã€‚å­©å­ä»¬é½å¿ƒååŠ›ï¼Œé€šè¿‡æµ·æŠ¥å’Œç¤¾äº¤åª’ä½“ä¼ æ’­æ¶ˆæ¯ã€‚æœ€ç»ˆï¼Œä¸€ä½å–„è‰¯çš„é‚»å±…æ‰¾åˆ°äº†å°çŒ«ï¼Œå°é•‡å› æ­¤æ´‹æº¢ç€æ¬¢ç¬‘å’Œæ„Ÿæ¿€çš„æ°”æ°›ã€‚"],
        ["LLM-Detector-Small-zh", "æœºå™¨å­¦ä¹ æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºé€šè¿‡ä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼å’Œè§„å¾‹ï¼Œè®©è®¡ç®—æœºç³»ç»Ÿå…·å¤‡è‡ªä¸»å­¦ä¹ çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜ç¡®åœ°è¿›è¡Œç¼–ç¨‹ã€‚é€šè¿‡è®­ç»ƒæ¨¡å‹ï¼Œæœºå™¨å­¦ä¹ ä½¿è®¡ç®—æœºèƒ½å¤Ÿä»ç»éªŒä¸­å­¦åˆ°å¹¶æé«˜æ€§èƒ½ï¼Œä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€é¢„æµ‹ã€è¯†åˆ«æ¨¡å¼ç­‰ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œç®—æ³•é€šè¿‡ä¸æ–­ä¼˜åŒ–è‡ªèº«ä»¥é€‚åº”æ–°æ•°æ®ï¼Œä»è€Œæ”¹å–„å…¶æ€§èƒ½ã€‚"],
        ["LLM-Detector-Small-en","I strongly believe that the Electoral College should remain the way it is or, better yet, that we should elect the president by popular vote. This is due to the fact that the Electoral College does not accurately reflect the will of the people. For example, in the 2016 presidential election, an estimated two million more people voted for Hillary Clinton than for Donald Trump however, Trump won the Electoral College vote, 304 to 232. This means that a candidate can win a majority of the Electoral College voters while losing the popular vote! Furthermore, voting for President should be an individual citizen decision, not a state decision. The Electoral College works by awarding all of a state's electoral votes to the winner of the majority of votes in the state. This means that a candidate can win the majority of votes in a state and still not receive any of that states electoral votes. This goes against the concept of onepersononevote, since a candidate can win the majority of votes in a state and still not win any electoral votes. By eliminating the Electoral College and electing the president by popular vote, the votes of every individual will be counted, and the candidate who wins the most votes nationally will win the election. In conclusion, the Electoral College does not reflect the will of the people and votes in state are not equally weighted. It is time to elect the president by popular vote and to finally give the votes of individual citizens the weight they deserve."],
        ],
        inputs=[select_model, input_text]
    )
    
    gr.Markdown("#### æ–‡å¿ƒä¸€è¨€æ–‡æœ¬ç¤ºä¾‹")
    gr.Examples(
        [
        ["LLM-Detector-Small-zh", "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯æŒ‡ä½¿ç”¨å¤§é‡æ–‡æœ¬æ•°æ®è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬æˆ–ç†è§£è¯­è¨€æ–‡æœ¬çš„å«ä¹‰ã€‚å¤§è¯­è¨€æ¨¡å‹å¯ä»¥å¤„ç†å¤šç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€é—®ç­”ã€å¯¹è¯ç­‰ï¼Œæ˜¯é€šå‘äººå·¥æ™ºèƒ½çš„ä¸€æ¡é‡è¦é€”å¾„ã€‚å¤§è¯­è¨€æ¨¡å‹çš„ç‰¹ç‚¹æ˜¯è§„æ¨¡åºå¤§ï¼ŒåŒ…å«æ•°åäº¿çš„å‚æ•°ï¼Œå¸®åŠ©å®ƒä»¬å­¦ä¹ è¯­è¨€æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚è¿™äº›æ¨¡å‹é€šå¸¸åŸºäºæ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå¦‚è½¬åŒ–å™¨ï¼Œè¿™æœ‰åŠ©äºå®ƒä»¬åœ¨å„ç§NLPä»»åŠ¡ä¸Šå–å¾—ä»¤äººå°è±¡æ·±åˆ»çš„è¡¨ç°ã€‚ç›®å‰çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPTå’ŒBERTï¼‰é‡‡ç”¨ä¸å°æ¨¡å‹ç±»ä¼¼çš„Transformeræ¶æ„å’Œé¢„è®­ç»ƒç›®æ ‡ï¼ˆå¦‚Language Modelingï¼‰ï¼Œä¸å°æ¨¡å‹çš„ä¸»è¦åŒºåˆ«åœ¨äºå¢åŠ æ¨¡å‹å¤§å°ã€è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚"],
        ["LLM-Detector-Small-zh", "å°Šæ•¬çš„ç»ç†ï¼Œæˆ‘å†™è¿™å°é‚®ä»¶æ˜¯æƒ³å‘æ‚¨ç”³è¯·åœ¨æ¥ä¸‹æ¥çš„ä¸‰å¤©å†…è¯·å‡ã€‚ç”±äºå®¶åº­åŸå› ï¼Œæˆ‘éœ€è¦å¤„ç†ä¸€äº›ç§äº‹ï¼Œå› æ­¤å¸Œæœ›èƒ½å¤Ÿå¾—åˆ°æ‚¨çš„ç†è§£å’Œæ”¯æŒã€‚æˆ‘ä¿è¯åœ¨è¯·å‡æœŸé—´å°½ä¸€åˆ‡åŠªåŠ›ç¡®ä¿æˆ‘çš„å·¥ä½œä¸ä¼šå½±å“åˆ°å›¢é˜Ÿçš„æ­£å¸¸è¿ä½œã€‚æˆ‘å·²ç»åšå¥½äº†å·¥ä½œå®‰æ’ï¼Œå¹¶ä¸åŒäº‹åå•†å¥½äº†ç›¸å…³å·¥ä½œäº‹å®œã€‚å¦‚æœæ‚¨èƒ½å¤Ÿæ‰¹å‡†æˆ‘çš„è¯·å‡ç”³è¯·ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦è¿›ä¸€æ­¥çš„ä¿¡æ¯ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ã€‚è°¢è°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒã€‚é¡ºç¥å•†ç¥ºï¼"],
        ["LLM-Detector-Small-en","My name is XX, a passionate and outgoing individual. I have a strong interest in learning new things and am always eager to explore new experiences and opportunities. With a Bachelor's degree in Computer Science, I possess a strong foundation in technology and enjoy utilizing my skills to solve complex problems. As a self-motivated and goal-oriented person, I thrive in fast-paced and challenging environments. I take pride in my adaptability and ability to quickly grasp new concepts, regardless of the domain. With my strong communication skills, I can easily work with colleagues and clients to achieve common goals. In my free time, I enjoy reading books, playing basketball, and traveling to new places. I believe that travel is an excellent way to gain perspective and broaden one's horizons. In conclusion, I am a skilled professional with a strong educational background and a broad range of skills. I am confident in my abilities and am always looking for opportunities to grow and develop professionally. "]
        ],
        inputs=[select_model, input_text]
    )
    
    gr.Markdown("## ğŸ¥¨ç‰¹æ®Šæµ‹è¯•")
    gr.Markdown("#### æ ‡ç‚¹ç¬¦å·")
    gr.Examples(
        [
        ["LLM-Detector-Small-zh", "ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©"],
        ["LLM-Detector-Small-zh", "ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©ï¼Ÿ"],
        ],
        inputs=[select_model, input_text]
    )
    
    gr.HTML("<img src=\"https://img.lecter.one/i/2023/12/08/irw9rv.png\">")
    gr.HTML("<center><a href=\'https://clustrmaps.com/site/1bxsq\'  title=\'Visit tracker\'><img src=\'//clustrmaps.com/map_v2.png?cl=4148bc&w=a&t=tt&d=_GWhYr_Z4pFr-TUk17Zm_vc3VtJsdHrhC9WCDT5wNFo&co=ffffff&ct=441616\'/></a></center>")
    gr.HTML("<center><p>Â© 2023 LLM-Detector. If you have any issue, feel free to contact us by <a href=\"mailto:wrs6@88.com\">wrs6@88.com</a>. Our Github is <a href=\"https://github.com/QiYuan-tech\">QiYuan.Tech</a>.</p></center>")
    
theme=gr.themes.Base()
demo.title = "LLM-Detector ğŸš€"
demo.queue(max_size=6)         
demo.launch()
